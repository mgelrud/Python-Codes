{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105732\n"
     ]
    }
   ],
   "source": [
    "# Importing a table with Datastream output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "table_list = []\n",
    "for i in range(1, 11):\n",
    "    title = 'Datastream Output/Datastream Output ' + str(i) + '.xlsx'\n",
    "    single = pd.read_excel(title)\n",
    "    single_list = single.values.tolist()    \n",
    "    table_list.extend(single_list)\n",
    "print(len(table_list))\n",
    "#print(table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing a list of DS Codes and companies\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "codes_comps = np.load('Datastream Tickers/ds_codes_and_comps.npy')\n",
    "codes_comps = codes_comps.tolist()\n",
    "del codes_comps[105731]\n",
    "del codes_comps[105731]\n",
    "del codes_comps[105731]    \n",
    "#print(codes_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding DS Codes to the table\n",
    "\n",
    "for i in range(len(table_list)):\n",
    "    table_list[i].append(codes_comps[i][0])\n",
    "    table_list[i].append(codes_comps[i][2])\n",
    "#print(table_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106133\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary with names as keys and companies as values\n",
    "\n",
    "dict = {}\n",
    "for i in range(len(table_list)):\n",
    "    for j in range(2, 6):\n",
    "        if str(table_list[i][j]) != \"nan\":\n",
    "            words_list = table_list[i][j].split()\n",
    "            for k in range(len(words_list)):\n",
    "                words_list[k] = words_list[k].lower()\n",
    "            words_list.sort()    \n",
    "            words_list = \" \".join(words_list)    \n",
    "            if words_list not in dict:\n",
    "                dict[words_list] = [(table_list[i][6], table_list[i][0], table_list[i][1], table_list[i][7])]\n",
    "            else:\n",
    "                dict[words_list].append((table_list[i][6], table_list[i][0], table_list[i][1], table_list[i][7]))\n",
    "print(len(dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving the new dictionary to a file\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('datastream_officers_dict.pickle', 'wb') as whatever:\n",
    "  pickle.dump(dict, whatever)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190297\n",
      "178250\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of names as sets of words\n",
    "\n",
    "names_list = []\n",
    "names_list_no_chinese = []\n",
    "for i in range(len(table_list)):    \n",
    "    for j in range(2, 6):\n",
    "        if str(table_list[i][j]) != \"nan\":\n",
    "            words_list = table_list[i][j].split()\n",
    "            words_set = set()\n",
    "            for k in range(len(words_list)):\n",
    "                words_list[k] = words_list[k].lower()\n",
    "                words_set.update({words_list[k]})\n",
    "            names_list.append(words_set)\n",
    "            if table_list[i][1] != \"CHINA\":\n",
    "                names_list_no_chinese.append(words_set)\n",
    "print(len(names_list))   \n",
    "print(len(names_list_no_chinese))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106122\n",
      "99126\n"
     ]
    }
   ],
   "source": [
    "# Eliminating identical names from the lists\n",
    "\n",
    "names_list_unique = []\n",
    "for i in range(len(names_list)):\n",
    "    if names_list[i] not in names_list_unique:\n",
    "        names_list_unique.append(names_list[i])\n",
    "print(len(names_list_unique))   \n",
    "\n",
    "names_list_unique_no_chinese = []\n",
    "for i in range(len(names_list_no_chinese)):\n",
    "    if names_list_no_chinese[i] not in names_list_unique_no_chinese:\n",
    "        names_list_unique_no_chinese.append(names_list_no_chinese[i])\n",
    "print(len(names_list_unique_no_chinese)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Saving the list of names to a file\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.save('datastream_names_list.npy', names_list_unique)\n",
    "np.save('datastream_names_list_no_chinese.npy', names_list_unique_no_chinese)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
